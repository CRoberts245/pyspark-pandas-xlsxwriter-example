{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65051897-1c92-4b87-9704-017b01270fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from decimal import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os, os.path\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from pathlib import Path  # Python 3.6+ only\n",
    "import xlsxwriter\n",
    "from datetime import date\n",
    "\n",
    "#loads env vars from local .env file\n",
    "def load_env():\n",
    "    #set .env path and load \n",
    "    env_path = Path('.') / '.env'\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "#creates generic HTTP session/request\n",
    "def create_HTTP_session():\n",
    "    #create a requests session to get/post; HTTPS with HTTPAdapter\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[ 500, 502, 503, 504 ])\n",
    "    s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    return s\n",
    "\n",
    "#uses session/request to get authentication response JSON for springcm\n",
    "def get_springcm_authentication(session, client_id, client_secret):\n",
    "    # Get access token and API base URL\n",
    "    response = session.post(\n",
    "        \"https://auth.springcm.com/api/v201606/apiuser\",\n",
    "        data={\"client_id\": client_id, \"client_secret\": client_secret},\n",
    "    )\n",
    "    authentication_response = response.json()\n",
    "    return authentication_response\n",
    "\n",
    "#downloads single scpringcm file by ID, example call: download_springcm_file_by_ID(os.environ.get('SERVICES_HOURS'), auth_response, 'Services by Hour.csv', old_path, s)\n",
    "def download_springcm_file_by_ID(ID, authentication_response, dest_document_name, dest_folder_path, session):\n",
    "    response = session.get(\n",
    "        \"https://apidownloadna11.springcm.com/v201411/documents/\" + ID,\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer \" + authentication_response[\"access_token\"],\n",
    "        },\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(dest_folder_path), exist_ok=True)\n",
    "    with open(dest_folder_path + dest_document_name, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "#downloads all files in a given springcm folder, example call: download_springcm_all_files(auth_response, './agstarData/', s, \"/AgStar Data/New AgStar Reports\") LEAVE OUT \"Wegis and/& Young\"\n",
    "def download_springcm_all_files(authentication_response, dest_folder_path, session, springcm_folder_path):\n",
    "    # Get folder paths\n",
    "    response = session.get(\n",
    "        \"https://apina11.springcm.com/v201411/folders\",\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer \" + authentication_response[\"access_token\"],\n",
    "        },\n",
    "        params={\n",
    "            \"path\": springcm_folder_path,\n",
    "            \"expand\": \"documents,folders\",\n",
    "            \"limit\": 100,\n",
    "        },\n",
    "    )\n",
    "    folder_response = response.json()\n",
    "\n",
    "    # Grab all documents in folder\n",
    "    document_list = {}\n",
    "    for document in folder_response['Documents']['Items']:\n",
    "        document_list.update({document['Name']: document['DownloadDocumentHref']})\n",
    "    for document_name in document_list:\n",
    "        document_id = document_list[document_name]\n",
    "        response = session.get(\n",
    "            document_id,\n",
    "            headers={\n",
    "            \"Authorization\": \"Bearer \" + authentication_response['access_token'],\n",
    "        }\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(dest_folder_path), exist_ok=True)\n",
    "        with open(dest_folder_path + document_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "#assigns a row number to a dataframe, returns dataframe\n",
    "def assignRowNum(dataframe):\n",
    "    \n",
    "    w = Window().orderBy(lit('A'))\n",
    "    dataframe = dataframe.withColumn('row_num', row_number().over(w))\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "#fills oldColumnName down/forwards, gives newColumnName\n",
    "def fillColumnDown(dataframe, partitionBy, orderBy, oldColumnName, newColumnName):\n",
    "        \n",
    "        window = (\n",
    "        Window\n",
    "        .partitionBy(partitionBy)\n",
    "        .orderBy(orderBy)\n",
    "        .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "      )\n",
    "        \n",
    "        dataframe = dataframe.withColumn(newColumnName, last(oldColumnName, ignorenulls=True).over(window)) \n",
    "       \n",
    "        \n",
    "        return dataframe\n",
    "\n",
    "#splits columns by pipe with custom parameters\n",
    "def customPipeSplit(dataframe, price, units, service, percent):   \n",
    "    dataframe = dataframe.withColumn('split_table',\n",
    "                        explode(\n",
    "                        arrays_zip(\n",
    "                        split(col(units), '\\\\|').alias(\"units_arr\")\n",
    "                       ,split(col(service), '\\\\|').alias(\"service_arr\")\n",
    "                       ,split(col(price), '\\\\|').alias(\"price_arr\")\n",
    "                       ,split(col(percent), '\\\\|').alias(\"percent_arr\"))))\n",
    "\n",
    "    dataframe = dataframe.withColumn('PRICE', col('split_table')['price_arr']) \\\n",
    "          .withColumn('PERCENT', col('split_table')['percent_arr']) \\\n",
    "          .withColumn('SERVICE', col('split_table')['service_arr']) \\\n",
    "          .withColumn('BILLABLE UNITS', col('split_table')['units_arr']) \\\n",
    "          .drop('split_table')\n",
    "    return dataframe\n",
    "\n",
    "#adds a row of all spaces after each group\n",
    "def addSpaceAfterGroupPandas(df,group):\n",
    "    # reset index \n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    # find the border idx of InvoiceNumber\n",
    "    idx_list = df.drop_duplicates(group, keep='last').index\n",
    "\n",
    "    # use the border idx, create an empty df, and concat to the origin df, then sort the index\n",
    "    df_append = pd.DataFrame('', index = idx_list, columns = df.columns)\n",
    "    df = pd.concat([df,df_append]).sort_index()                 \n",
    "    \n",
    "    \n",
    "    #reset index and drop unused columns\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by=['index', group],ascending = [True, True])  \n",
    "    df.drop([group, 'index'], axis=1, inplace=True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "#replaces prices on tickets with prices in services\n",
    "def replace_prices(dataframe, prices_data):\n",
    "    #drop row number\n",
    "    dataframe = dataframe.drop('row_num')\n",
    "\n",
    "    #cast as floats, round billable units to 2 decimal places\n",
    "    dataframe = dataframe.withColumn(\"PRICE\",col(\"PRICE\").cast('Decimal(20,2)')) \\\n",
    "           .withColumn(\"BLANK\",lit('')) \\\n",
    "           .withColumn(\"PERCENT\",col(\"PERCENT\").cast('Decimal(20,2)')) \\\n",
    "           .withColumn(\"BILLABLE UNITS\",   col(\"BILLABLE UNITS\").cast('Decimal(20,2)')) \\\n",
    "           .withColumn(\"BILLABLE UNITS\",   (col(\"BILLABLE UNITS\")*(col(\"PERCENT\")/100.00)).cast(DecimalType(20,2)))  \\\n",
    "\n",
    "\n",
    "\n",
    "    #joining services prices and renaming columns\n",
    "    dataframe = dataframe.join(prices,(dataframe.SERVICE == prices_data.SERVICE_P) & (dataframe.UNITS == prices_data.UNITS_P)) \\\n",
    "           .drop('SERVICE', 'PRICE','UNITS') \\\n",
    "           .withColumnRenamed(\"PRICE_P\", \"PRICE\") \\\n",
    "           .withColumnRenamed(\"SERVICE_P\", \"SERVICE\") \\\n",
    "           .withColumnRenamed(\"UNITS_P\", \"UNITS\") \n",
    "    return dataframe\n",
    "\n",
    "#union price by acre/hour\n",
    "def prices_by_unit_union(price_by_acre, price_by_hour):\n",
    "    #--------------------------------\n",
    "    #rename Services by Acre AND Services by Hour to column match\n",
    "    price_by_acre = price_by_acre.withColumn(\"PRICE\",col(\"Price per Acre\").cast('Decimal(20,2)')) \\\n",
    "                             .withColumn('UNITS', lit('Acres')) \\\n",
    "                             .withColumnRenamed('Service by Acre', 'SERVICE') \\\n",
    "                            .drop('Service by Acre', \"Price per Acre\")\n",
    "\n",
    "    price_by_hour = price_by_hour.withColumn(\"PRICE\",col(\"Price per Hour\").cast('Decimal(20,2)'))    \\\n",
    "                             .withColumn('UNITS', lit('Hours')) \\\n",
    "                             .withColumnRenamed('Service by Hour', 'SERVICE') \\\n",
    "                             .drop('Service by Hour', \"Price per Hour\")  \n",
    "\n",
    "    # Union Services by Acre AND Services by Hour   \n",
    "    prices = price_by_hour.union(price_by_acre)\n",
    "\n",
    "    #renaming columns to avoid conflicts below\n",
    "    prices = prices.withColumnRenamed(\"PRICE\", \"PRICE_P\") \\\n",
    "               .withColumnRenamed(\"SERVICE\", \"SERVICE_P\") \\\n",
    "               .withColumnRenamed(\"UNITS\", \"UNITS_P\")\n",
    "    return prices\n",
    "\n",
    "#unions tickets by acre and tickets by hour, pipe split, fill down, replace prices with services\n",
    "def tickets_union(service_by_acre, service_by_hour, prices):\n",
    "        #drop unused columns \n",
    "    service_by_acre = service_by_acre.drop('RANCH MANAGER', 'DOCUMENT NAME', 'DATE', 'STATUS', 'REC NUMBER','NOTES')\n",
    "\n",
    "    #rename columns, add literals \n",
    "    service_by_acre = service_by_acre.withColumnRenamed('SERVICE BY ACRE', 'SERVICE') \\\n",
    "                                 .withColumnRenamed('ACRES', 'BILLABLE UNITS') \\\n",
    "                                 .withColumnRenamed('PRICE PER ACRE', 'PRICE') \\\n",
    "                                 .withColumn('UNITS', lit('Acres'))\n",
    "    #drop unused columns \n",
    "    service_by_hour = service_by_hour.drop('RANCH MANAGER', 'DOCUMENT NAME', 'DATE', 'STATUS', 'REC NUMBER', 'ACRES', 'NOTES')\n",
    "\n",
    "    #rename columns , add literals \n",
    "    service_by_hour = service_by_hour.withColumnRenamed('SERVICE BY HOUR', 'SERVICE') \\\n",
    "                                 .withColumnRenamed('HOURS', 'BILLABLE UNITS') \\\n",
    "                                 .withColumnRenamed('PRICE PER HOUR', 'PRICE') \\\n",
    "                                 .withColumn('PERCENT', lit('100')) \\\n",
    "                                 .withColumn('UNITS', lit('Hours'))\n",
    "\n",
    "    #union Service by Hour AND Service by Acre\n",
    "    tickets = service_by_hour.union(service_by_acre)\n",
    "    \n",
    "     #custom split\n",
    "    tickets = customPipeSplit(tickets, 'PRICE', 'BILLABLE UNITS', 'SERVICE', 'PERCENT')\n",
    "\n",
    "    #assign row numbers\n",
    "    tickets = assignRowNum(tickets)\n",
    "\n",
    "    #fill down on columns\n",
    "    tickets = fillColumnDown(tickets, 'FIELD TICKET NUMBER', 'row_num', 'BILLABLE UNITS', 'BILLABLE UNITS')\n",
    "    tickets = fillColumnDown(tickets, 'FIELD TICKET NUMBER', 'row_num', 'PRICE', 'PRICE')\n",
    "    tickets = fillColumnDown(tickets, 'FIELD TICKET NUMBER', 'row_num', 'PERCENT', 'PERCENT')\n",
    "    tickets = fillColumnDown(tickets, 'FIELD TICKET NUMBER', 'row_num', 'SERVICE', 'SERVICE')\n",
    "\n",
    "    #replace prices in tickets with prices from services\n",
    "    tickets = replace_prices(tickets, prices)\n",
    "    \n",
    "    return tickets\n",
    "\n",
    "#create FT to Archive file\n",
    "def field_ticket_archive(tickets, folder_path):\n",
    "       \n",
    "    #create FT to Archive CSV\n",
    "    to_archive = assignRowNum(tickets)\n",
    "    to_archive = to_archive.withColumnRenamed('row_num', 'ROWID')\n",
    "    to_archive.toPandas().to_csv(folder_path + 'Service for AgStar - FT to Archive.csv',header = True, index = False)\n",
    "    \n",
    "#creates agstar report, requires tempview sql from spark named field _tickets\n",
    "def create_agstar_csv(agstar_report_path):  \n",
    "    #select agstar report                   \n",
    "    agstar = spark.sql(\"SELECT `CUSTOMER NUMBER`                                                                    \\\n",
    "                       , DENSE_RANK() OVER (ORDER BY COMPANY ASC)AS InvoiceNumber                                   \\\n",
    "                       , DATE_FORMAT(DATE_ADD(LAST_DAY(ADD_MONTHS(CURRENT_DATE(), -1)), 1), 'M/d/yyyy') AS DATE1                    \\\n",
    "                       , DENSE_RANK() OVER (PARTITION BY COMPANY ORDER BY SERVICE ASC, UNITS ASC) AS LineSeq        \\\n",
    "                       , ACCOUNT                                                                                    \\\n",
    "                       , ROUND(SUM(`BILLABLE UNITS`)*PRICE,2) AS TOTAL                                              \\\n",
    "                       , BLANK                                                                                      \\\n",
    "                       , DATE_FORMAT(LAST_DAY(CURRENT_DATE()), 'M/d/yyyy') AS DATE2                  \\\n",
    "                       , SERVICE                                                                                    \\\n",
    "                       , SUM(`BILLABLE UNITS`) AS `BILLABLE UNITS`                                                  \\\n",
    "                       , UNITS                                                                                      \\\n",
    "                       , PRICE                                                                                      \\\n",
    "                       , 'N'                                                                                        \\\n",
    "                       , `COST CENTER`                                                                              \\\n",
    "                       , '0'                                                                                        \\\n",
    "                        FROM field_tickets                                                                          \\\n",
    "                        GROUP BY  COMPANY                                                                           \\\n",
    "                                , SERVICE                                                                           \\\n",
    "                                , `CUSTOMER NUMBER`                                                                 \\\n",
    "                                , ACCOUNT                                                                           \\\n",
    "                                , UNITS                                                                             \\\n",
    "                                , `COST CENTER`                                                                     \\\n",
    "                                , PRICE                                                                             \\\n",
    "                                , BLANK                                                                             \\\n",
    "                        ORDER BY  COMPANY                                                                           \\\n",
    "                                , SERVICE \")\n",
    "    #convert to pandas for transformation/writes csv\n",
    "    agstar.toPandas().to_csv(agstar_report_path, header = False, index = False)\n",
    "\n",
    "#creates xlsx file customer detail report, requires tempview from spark named field _tickets\n",
    "def create_customer_detail_xlsx(customer_detail_report_path):\n",
    "    \n",
    "    \n",
    "        #select customer detail report\n",
    "    customer_detail = spark.sql(\"SELECT COMPANY                                                                     \\\n",
    "                               , `FIELD TICKET NUMBER` AS `Ticket Number`                                          \\\n",
    "                               , FIELD  AS Field                                                                   \\\n",
    "                               , `BILLABLE UNITS`  AS `Acres/Hours`                                                \\\n",
    "                               , SERVICE AS Service                                                                \\\n",
    "                               , PRICE AS Price                                                                    \\\n",
    "                               , `BILLABLE UNITS`*PRICE AS `Line Total`                                            \\\n",
    "                               , DENSE_RANK() OVER (ORDER BY COMPANY ASC) AS InvoiceNumber                         \\\n",
    "                               , DATE_FORMAT(DATE_ADD(LAST_DAY(ADD_MONTHS(CURRENT_DATE(), -1)), 1), 'M/d/yyyy') AS DATE1                    \\\n",
    "                               , DATE_FORMAT(LAST_DAY(CURRENT_DATE()), 'M/d/yyyy') AS DATE2                  \\\n",
    "                               FROM field_tickets                                                                  \\\n",
    "                               ORDER BY COMPANY                                                                    \\\n",
    "                                       ,SERVICE \")\n",
    "    #convert to pandas for transformation\n",
    "    customer_detail = customer_detail.toPandas()\n",
    "    \n",
    "    \n",
    "    workbook = xlsxwriter.Workbook(customer_detail_report_path)\n",
    "\n",
    "    bold_centered = workbook.add_format({'bold': 1})\n",
    "    bold_centered.set_align('vcenter')\n",
    "    bold_centered.set_align('hcenter')\n",
    "    bold1 = workbook.add_format({'bold': 1})\n",
    "    bold1.set_bottom()\n",
    "    bold1.set_top()\n",
    "    bold2 = workbook.add_format({'bold': 1,'num_format': '$#,##0.00'})\n",
    "    bold2.set_bottom(2)\n",
    "    bold2.set_top()\n",
    "    center = workbook.add_format()\n",
    "    center.set_align('vcenter')\n",
    "    format1 = workbook.add_format({'num_format': '#,##0.00'})\n",
    "    format1.set_pattern(1)\n",
    "    format1.set_bg_color('#D9D9D9')\n",
    "    format2 = workbook.add_format({'num_format': '#,##0.00'})\n",
    "    \n",
    "    for i in range(customer_detail['InvoiceNumber'].max()):\n",
    "        df1 = customer_detail[customer_detail['InvoiceNumber'] == i+1]\n",
    "        company = df1['COMPANY'].iloc[0]\n",
    "        ws = workbook.add_worksheet(company)\n",
    "        if '&' in company:\n",
    "            string = company.split('&')\n",
    "            company = string[0] + '&&' + string[1]\n",
    "        ws.set_header('&C&18&\"Calibri,Bold\"' + company)\n",
    "        ws.write('A1', 'Invoice #' + str(i+1), bold_centered)\n",
    "        ws.write('D1', 'Date Range:', bold_centered)\n",
    "        ws.write('E1', df1['DATE1'].iloc[0],center)\n",
    "        ws.write('F1', df1['DATE2'].iloc[0],center)\n",
    "        ws.write('A2', 'Ticket Number', bold1)\n",
    "        ws.write('B2', 'Field', bold1)\n",
    "        ws.write('C2', 'Acres/Hours', bold1)\n",
    "        ws.write('D2', 'Service', bold1)\n",
    "        ws.write('E2', 'Price', bold1)\n",
    "        ws.write('F2', 'Line Total', bold1)\n",
    "        ws.set_column(0, 0, 15.43)\n",
    "        ws.set_column(2, 2, 10)\n",
    "        ws.set_column(3, 3, 15.14)\n",
    "        ws.set_column(4, 4, 12.57)\n",
    "        ws.set_column(5, 5, 14.29)\n",
    "        ws.set_row(0, 52.5)\n",
    "        ws.set_page_view()\n",
    "        df1 = df1.reset_index(drop = True)\n",
    "        for i in range(0 ,df1.last_valid_index()+1, 2):\n",
    "            ws.write('A'+ str(i+3), df1['Ticket Number'].iloc[i], format1)\n",
    "            ws.write('B'+ str(i+3), df1['Field'].iloc[i], format1)\n",
    "            ws.write('C'+ str(i+3), df1['Acres/Hours'].iloc[i], format1)\n",
    "            ws.write('D'+ str(i+3), df1['Service'].iloc[i], format1)\n",
    "            ws.write('E'+ str(i+3), df1['Price'].iloc[i], format1)\n",
    "            ws.write('F'+ str(i+3), df1['Line Total'].iloc[i], format1)\n",
    "\n",
    "            if(i == df1.last_valid_index()):\n",
    "                break\n",
    "            ws.write('A'+ str(i+4), df1['Ticket Number'].iloc[i+1], format2)\n",
    "            ws.write('B'+ str(i+4), df1['Field'].iloc[i+1], format2)\n",
    "            ws.write('C'+ str(i+4), df1['Acres/Hours'].iloc[i+1], format2)\n",
    "            ws.write('D'+ str(i+4), df1['Service'].iloc[i+1], format2)\n",
    "            ws.write('E'+ str(i+4), df1['Price'].iloc[i+1], format2)\n",
    "            ws.write('F'+ str(i+4), df1['Line Total'].iloc[i+1], format2)\n",
    "\n",
    "        ws.write('A'+ str(df1.last_valid_index()+4) , 'Total:', bold2)\n",
    "        ws.write('B'+ str(df1.last_valid_index()+4) , '', bold2)\n",
    "        ws.write('C'+ str(df1.last_valid_index()+4) , '', bold2)\n",
    "        ws.write('D'+ str(df1.last_valid_index()+4) , '', bold2)\n",
    "        ws.write('E'+ str(df1.last_valid_index()+4) , '', bold2)\n",
    "        ws.write('F'+ str(df1.last_valid_index()+4) , '=SUM(F3:F' + str(df1.last_valid_index()+3) + ')', bold2)\n",
    "    workbook.close()\n",
    "##################################################################################\n",
    "#load env vars; access via os.environ.get('VAR')\n",
    "load_env()\n",
    "\n",
    "#create HTTP session with retries etc\n",
    "s = create_HTTP_session()\n",
    "\n",
    "#get auth info from springcm\n",
    "auth_response = get_springcm_authentication(s, os.environ.get('CLIENT_ID'), os.environ.get('CLIENT_SECRET'))\n",
    "\n",
    "#date info\n",
    "today = date.today()\n",
    "today = today.strftime(\"%b-%d-%Y\")\n",
    "\n",
    "#assign folder/file paths to local OLD/NEW\n",
    "old_folder_path = './agstarDataOld/'\n",
    "new_folder_path = './agstarDataNew/'\n",
    "services_acre = 'Services by Acre.csv'\n",
    "services_hour = 'Services by Hour.csv'\n",
    "tickets_acre = 'Service By Acre for AgStar Import.csv'\n",
    "tickets_hour = 'Service By Hour for AgStar Import.csv'\n",
    "customer_detail_report_path = new_folder_path + 'Customer Detail Report ' + today + '.xlsx'\n",
    "agstar_report_path = new_folder_path + 'AgStar Report ' + today + '.csv'\n",
    "\n",
    "#make sure old and new folders are created\n",
    "os.makedirs(os.path.dirname(new_folder_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(old_folder_path), exist_ok=True)\n",
    "\n",
    "#Download Services by Acre/Hour.csv    \n",
    "download_springcm_file_by_ID(os.environ.get('SERVICES_ACRES'), auth_response, services_acre, old_folder_path, s)\n",
    "download_springcm_file_by_ID(os.environ.get('SERVICES_HOURS'), auth_response, services_hour, old_folder_path, s)\n",
    "\n",
    "#Download Service By Hour/Acre for AgStar Import.csv   \n",
    "download_springcm_file_by_ID(os.environ.get('TICKETS_ACRES'), auth_response, tickets_acre, old_folder_path, s)\n",
    "download_springcm_file_by_ID(os.environ.get('TICKETS_HOURS'), auth_response, tickets_hour, old_folder_path, s)\n",
    "\n",
    "#creating spark session\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"CRoberts\").getOrCreate()  \n",
    "\n",
    "#open Service/Prices by Acres AND Service/Prices by Hours \n",
    "price_by_acre =  spark.read.option(\"header\",True).option(\"multiline\", \"true\").csv(old_folder_path+services_acre)\n",
    "price_by_hour =  spark.read.option(\"header\",True).option(\"multiline\", \"true\").csv(old_folder_path+services_hour) \n",
    "#open Service by Hour/Acre\n",
    "service_by_hour =  spark.read.option(\"header\",True).option(\"multiline\", \"true\").csv(old_folder_path+tickets_hour)\n",
    "service_by_acre =  spark.read.option(\"header\",True).option(\"multiline\", \"true\").csv(old_folder_path+tickets_acre)\n",
    "\n",
    "#union all service prices together with units\n",
    "prices = prices_by_unit_union(price_by_acre, price_by_hour)\n",
    "\n",
    "#union field tickets, and replace with cprices with corrected prices \n",
    "tickets = tickets_union(service_by_acre, service_by_hour, prices)\n",
    "\n",
    "#create FT to Archive file\n",
    "field_ticket_archive(tickets, new_folder_path)\n",
    "\n",
    "#create ***GLOBAL*** sql queryable view\n",
    "tickets.createOrReplaceTempView(\"field_tickets\")\n",
    "#create agstar/customer detail files\n",
    "create_agstar_csv(agstar_report_path)\n",
    "create_customer_detail_xlsx(customer_detail_report_path)\n",
    "\n",
    "print('Success!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c029a033-3228-4f52-a7ae-190aa1fb07ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e67384ef-6bdf-49db-840c-c1cf6f44c36c\n",
      "{'Service By Hour for AgStar Import.csv': 'https://apidownloadna11.springcm.com/v201411/documents/270ae122-bdb9-ec11-9c48-d89d6716196d', 'Service By Acre for AgStar Import.csv': 'https://apidownloadna11.springcm.com/v201411/documents/630ae122-bdb9-ec11-9c48-d89d6716196d'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os, os.path\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OR, the same with increased verbosity\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "# OR, explicitly providing path to '.env'\n",
    "from pathlib import Path  # Python 3.6+ only\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Print variable FOO\n",
    "print(os.environ.get('CLIENT_ID')) # Returns 'BAR'\n",
    "\n",
    "s = requests.Session()\n",
    "retries = Retry(total=5,\n",
    "                backoff_factor=0.1,\n",
    "                status_forcelist=[ 500, 502, 503, 504 ])\n",
    "s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "# Get access token and API base URL\n",
    "response = s.post(\n",
    "    \"https://auth.springcm.com/api/v201606/apiuser\",\n",
    "    data={\"client_id\": os.environ.get('CLIENT_ID'), \"client_secret\": os.environ.get('CLIENT_SECRET')},\n",
    ")\n",
    "auth_response = response.json()\n",
    "# Get folder paths\n",
    "response = s.get(\n",
    "    \"https://apina11.springcm.com/v201411/folders\",\n",
    "    headers={\n",
    "        \"Authorization\": \"Bearer \" + auth_response[\"access_token\"],\n",
    "    },\n",
    "    params={\n",
    "        \"path\": \"/AgStar Data/New AgStar Reports\",\n",
    "        \"expand\": \"documents,folders\",\n",
    "        \"limit\": 100,\n",
    "    },\n",
    ")\n",
    "folder_response = response.json()\n",
    "\n",
    "\n",
    "# Grab all documents in folder\n",
    "document_list = {}\n",
    "for document in folder_response['Documents']['Items']:\n",
    "    document_list.update({document['Name']: document['DownloadDocumentHref']})\n",
    "print(document_list)\n",
    "for document_name in document_list:\n",
    "    document_id = document_list[document_name]\n",
    "    response = requests.get(\n",
    "        document_id,\n",
    "        headers={\n",
    "        \"Authorization\": \"Bearer \" + auth_response['access_token'],\n",
    "    }\n",
    "    )\n",
    "    os.makedirs(os.path.dirname('./agstarData/'), exist_ok=True)\n",
    "    with open('./agstarData/' + document_name, \"wb\") as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95831528-366a-45f9-ac30-2d3d6778d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e67384ef-6bdf-49db-840c-c1cf6f44c36c\n"
     ]
    }
   ],
   "source": [
    "# Example from https://pypi.org/project/python-dotenv/\n",
    "from dotenv import load_dotenv\n",
    "import os, os.path\n",
    "load_dotenv()\n",
    "\n",
    "# OR, the same with increased verbosity\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "# OR, explicitly providing path to '.env'\n",
    "from pathlib import Path  # Python 3.6+ only\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Print variable FOO\n",
    "print(os.environ.get('CLIENT_ID')) # Returns 'BAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa61151-1a87-43de-8360-42cc92179687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os, os.path\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from pathlib import Path  # Python 3.6+ only\n",
    "\n",
    "#loads env vars from local .env file\n",
    "def load_env():\n",
    "    #set .env path and load \n",
    "    env_path = Path('.') / '.env'\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "#creates generic HTTP session/request\n",
    "def create_HTTP_session():\n",
    "    #create a requests session to get/post; HTTPS with HTTPAdapter\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[ 500, 502, 503, 504 ])\n",
    "    s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    return s\n",
    "\n",
    "#uses session/request to get authentication response JSON for springcm\n",
    "def get_authentication(session, client_id, client_secret):\n",
    "    # Get access token and API base URL\n",
    "    response = session.post(\n",
    "        \"https://auth.springcm.com/api/v201606/apiuser\",\n",
    "        data={\"client_id\": client_id, \"client_secret\": client_secret},\n",
    "    )\n",
    "    authentication_response = response.json()\n",
    "    return authentication_response\n",
    "\n",
    "#downloads single scpringcm file by ID, example call: download_springcm_file_by_ID(os.environ.get('SERVICES_HOURS'), auth_response, 'Services by Hour.csv', old_path, s)\n",
    "def download_springcm_file_by_ID(ID, authentication_response, dest_document_name, dest_folder_path, session):\n",
    "    response = session.get(\n",
    "        \"https://apidownloadna11.springcm.com/v201411/documents/\" + ID,\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer \" + authentication_response[\"access_token\"],\n",
    "        },\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(dest_folder_path), exist_ok=True)\n",
    "    with open(dest_folder_path + dest_document_name, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "#downloads all files in a given springcm folder, example call: download_springcm_all_files(auth_response, './agstarData/', s, \"/AgStar Data/New AgStar Reports\") LEAVE OUT \"Wegis and/& Young\"\n",
    "def download_springcm_all_files(authentication_response, dest_folder_path, session, dl_folder_path):\n",
    "    # Get folder paths\n",
    "    response = session.get(\n",
    "        \"https://apina11.springcm.com/v201411/folders\",\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer \" + authentication_response[\"access_token\"],\n",
    "        },\n",
    "        params={\n",
    "            \"path\": dl_folder_path,\n",
    "            \"expand\": \"documents,folders\",\n",
    "            \"limit\": 100,\n",
    "        },\n",
    "    )\n",
    "    folder_response = response.json()\n",
    "\n",
    "    # Grab all documents in folder\n",
    "    document_list = {}\n",
    "    for document in folder_response['Documents']['Items']:\n",
    "        document_list.update({document['Name']: document['DownloadDocumentHref']})\n",
    "    for document_name in document_list:\n",
    "        document_id = document_list[document_name]\n",
    "        response = session.get(\n",
    "            document_id,\n",
    "            headers={\n",
    "            \"Authorization\": \"Bearer \" + authentication_response['access_token'],\n",
    "        }\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(dest_folder_path), exist_ok=True)\n",
    "        with open(dest_folder_path + document_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "#load env vars; access via os.environ.get('VAR')\n",
    "load_env()\n",
    "\n",
    "#create HTTP session with retries etc\n",
    "s = create_HTTP_session()\n",
    "\n",
    "#get auth info from springcm\n",
    "auth_response = get_authentication(s, os.environ.get('CLIENT_ID'), os.environ.get('CLIENT_SECRET'))\n",
    "\n",
    "#assign folder paths to local OLD/NEW\n",
    "old_path = './agstarDataOld/'\n",
    "new_path = './agstarDataNew/'\n",
    "\n",
    "#Download Services by Acre/Hour.csv    \n",
    "download_springcm_file_by_ID(os.environ.get('SERVICES_ACRES'), auth_response, 'Services by Acre.csv', old_path, s)\n",
    "download_springcm_file_by_ID(os.environ.get('SERVICES_HOURS'), auth_response, 'Services by Hour.csv', old_path, s)\n",
    "\n",
    "#Download Service By Hour/Acre for AgStar Import.csv   \n",
    "download_springcm_file_by_ID(os.environ.get('TICKETS_ACRES'), auth_response, 'Service By Acre for AgStar Import.csv', old_path, s)\n",
    "download_springcm_file_by_ID(os.environ.get('TICKETS_HOURS'), auth_response, 'Service By Hour for AgStar Import.csv', old_path, s)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe21e107-b4ac-4399-b7e9-de288ff7d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f51488-d995-4bd7-931f-15e9674e5206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 KB\u001b[0m \u001b[31m725.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5a2f8f-70fc-4aae-a8b0-95d0ded75941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.20.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44571731-5d19-431c-84df-bdb1b19394cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
